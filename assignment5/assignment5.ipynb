{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering and Gaussian Mixture Models (GMMs)\n",
    "\n",
    "Please complete the following assignment. Run all cells and submit your completed notebook through Gradescope.\n",
    "\n",
    "- Hierarchical clustering is a form of clustering that produces a **set of nested clusters organized in a tree**. It is visualized using a **Dendrogram** (tree-like diagram)\n",
    "\n",
    "#### In this assignment, the aim is to test your knowledge of Hierarchical clustering and GMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$$\n",
    "\\gamma_{ik} = \\frac{\\pi_k \\cdot \\mathcal{N}(x_i \\mid \\mu_k, \\Sigma_k)}{\\sum_{j=1}^{K} \\pi_j \\cdot \\mathcal{N}(x_i \\mid \\mu_j, \\Sigma_j)}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $\\gamma_{ik}$ is the responsibility of component $k$ for data point $i$.\n",
    "- $\\pi_k$ is the `weight` (or mixing coefficient) for component $k$.\n",
    "- $\\mathcal{N}(x_i \\mid \\mu_k, \\Sigma_k)$ is the Gaussian probability density function for data point $x_i$ given `mean $\\mu_k$` and `covariance $\\Sigma_k$`.\n",
    "- $K$ is the total number of components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 1. In hierarchical clustering, the dendrogram is used to\n",
    "\n",
    "    A) Visualize the data distribution\n",
    "    B) Represent the hierarchy of clusters\n",
    "    C) Compute the distance between clusters\n",
    "    D) Perform dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ans1():\n",
    "    return \"A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 2. Which of the following is **not** an assumption of Gaussian Mixture Models?\n",
    "    A) Data is generated from a mixture of Gaussian distributions\n",
    "    B) Clusters are independent\n",
    "    C) Each cluster has its own mean and covariance\n",
    "    D) All clusters have equal covariance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ans2():\n",
    "    return \"A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 3. Implement hierarchical clustering using SciPy on a generated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "##### 3a. Do the following:\n",
    "- Write a function that takes as input a dataset `X`. Perform a hierarchical clustering according to the following instructions.\n",
    "- Use the **SciPy Cluster Hierarchical linkage** method to and test the following **linkage** methods: ward, complete, average, and single.\n",
    "- Use the **Euclidean** distance metric.\n",
    "- For each linkage method, flatten the hierarchy to $k=2,3,4,5,6,7,8$ clusters and compute the **silhouette score** for each $k$.\n",
    "- Identify which combination of linkage method and cluster number with the `best silhouette score`.\n",
    "- Return a tuple consisting of `(linkage_matrix, linkage_method, k, silhouette score)` for the best linkage method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "def ans3a(X):\n",
    "    # Define linkage methods to test\n",
    "    linkage_methods = ['ward', 'complete', 'average', 'single']\n",
    "    best_score = -1\n",
    "    best_method = None\n",
    "    best_k = None\n",
    "    best_Z = None\n",
    "    for method in linkage_methods:\n",
    "        linkage_matrix = linkage(X, method=method, metric=\"euclidean\")\n",
    "        for k in range(2, 9):\n",
    "            clusters = fcluster(linkage_matrix, k)\n",
    "            if len(np.unique(clusters)) > 1:  # Ensure more than one cluster\n",
    "                score = silhouette_score(X, clusters)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_method = method\n",
    "                    best_k = k\n",
    "                    best_Z = linkage_matrix\n",
    "    \n",
    "    return (best_Z, best_method, best_k, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 300\n",
    "\n",
    "n_features = 2\n",
    "n_clusters = 4\n",
    "\n",
    "random_state = 42\n",
    "X, _ = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mans3a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mans3a\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m     17\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m fcluster(linkage_matrix, k)\n\u001b[0;32m---> 18\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[1;32m     20\u001b[0m         best_score \u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:141\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:299\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    297\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m    298\u001b[0m label_freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(labels)\n\u001b[0;32m--> 299\u001b[0m \u001b[43mcheck_number_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    302\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    303\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[1;32m    304\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:38\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Number of samples.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m n_labels \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;241m%\u001b[39m n_labels\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "ans3a(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q3a</pre> results:</strong></p><p><strong><pre style='display: inline;'>q3a - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        n_samples = 300\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        n_features = 2\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        n_clusters = 4\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        random_state = 42\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        X, _ = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features, random_state=random_state)\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        assert ans3a(X)[1] == 'ward'\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 6, in q3a 0\n",
       "    Failed example:\n",
       "        assert ans3a(X)[1] == 'ward'\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/doctest.py\", line 1350, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3a 0[5]>\", line 1, in <module>\n",
       "            assert ans3a(X)[1] == 'ward'\n",
       "          File \"/var/folders/52/s8kljfk54tn04dxr5wfrd8lm0000gn/T/ipykernel_40673/334630113.py\", line 18, in ans3a\n",
       "            score = silhouette_score(X, clusters)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 141, in silhouette_score\n",
       "            return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 299, in silhouette_samples\n",
       "            check_number_of_labels(len(le.classes_), n_samples)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 38, in check_number_of_labels\n",
       "            raise ValueError(\n",
       "        ValueError: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
       "    Trying:\n",
       "        assert ans3a(X)[2] == 4\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 7, in q3a 0\n",
       "    Failed example:\n",
       "        assert ans3a(X)[2] == 4\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/doctest.py\", line 1350, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3a 0[6]>\", line 1, in <module>\n",
       "            assert ans3a(X)[2] == 4\n",
       "          File \"/var/folders/52/s8kljfk54tn04dxr5wfrd8lm0000gn/T/ipykernel_40673/334630113.py\", line 18, in ans3a\n",
       "            score = silhouette_score(X, clusters)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 141, in silhouette_score\n",
       "            return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 299, in silhouette_samples\n",
       "            check_number_of_labels(len(le.classes_), n_samples)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 38, in check_number_of_labels\n",
       "            raise ValueError(\n",
       "        ValueError: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
       "    Trying:\n",
       "        assert 0.75 < ans3a(X)[3] < 0.85\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 8, in q3a 0\n",
       "    Failed example:\n",
       "        assert 0.75 < ans3a(X)[3] < 0.85\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/doctest.py\", line 1350, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3a 0[7]>\", line 1, in <module>\n",
       "            assert 0.75 < ans3a(X)[3] < 0.85\n",
       "          File \"/var/folders/52/s8kljfk54tn04dxr5wfrd8lm0000gn/T/ipykernel_40673/334630113.py\", line 18, in ans3a\n",
       "            score = silhouette_score(X, clusters)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 141, in silhouette_score\n",
       "            return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
       "            return func(*args, **kwargs)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 299, in silhouette_samples\n",
       "            check_number_of_labels(len(le.classes_), n_samples)\n",
       "          File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 38, in check_number_of_labels\n",
       "            raise ValueError(\n",
       "        ValueError: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
       "</pre>"
      ],
      "text/plain": [
       "q3a results:\n",
       "    q3a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            n_samples = 300\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            n_features = 2\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            n_clusters = 4\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            random_state = 42\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            X, _ = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features, random_state=random_state)\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            assert ans3a(X)[1] == 'ward'\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 6, in q3a 0\n",
       "        Failed example:\n",
       "            assert ans3a(X)[1] == 'ward'\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/doctest.py\", line 1350, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3a 0[5]>\", line 1, in <module>\n",
       "                assert ans3a(X)[1] == 'ward'\n",
       "              File \"/var/folders/52/s8kljfk54tn04dxr5wfrd8lm0000gn/T/ipykernel_40673/334630113.py\", line 18, in ans3a\n",
       "                score = silhouette_score(X, clusters)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 141, in silhouette_score\n",
       "                return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 299, in silhouette_samples\n",
       "                check_number_of_labels(len(le.classes_), n_samples)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 38, in check_number_of_labels\n",
       "                raise ValueError(\n",
       "            ValueError: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
       "        Trying:\n",
       "            assert ans3a(X)[2] == 4\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 7, in q3a 0\n",
       "        Failed example:\n",
       "            assert ans3a(X)[2] == 4\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/doctest.py\", line 1350, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3a 0[6]>\", line 1, in <module>\n",
       "                assert ans3a(X)[2] == 4\n",
       "              File \"/var/folders/52/s8kljfk54tn04dxr5wfrd8lm0000gn/T/ipykernel_40673/334630113.py\", line 18, in ans3a\n",
       "                score = silhouette_score(X, clusters)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 141, in silhouette_score\n",
       "                return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 299, in silhouette_samples\n",
       "                check_number_of_labels(len(le.classes_), n_samples)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 38, in check_number_of_labels\n",
       "                raise ValueError(\n",
       "            ValueError: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
       "        Trying:\n",
       "            assert 0.75 < ans3a(X)[3] < 0.85\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 8, in q3a 0\n",
       "        Failed example:\n",
       "            assert 0.75 < ans3a(X)[3] < 0.85\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/doctest.py\", line 1350, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3a 0[7]>\", line 1, in <module>\n",
       "                assert 0.75 < ans3a(X)[3] < 0.85\n",
       "              File \"/var/folders/52/s8kljfk54tn04dxr5wfrd8lm0000gn/T/ipykernel_40673/334630113.py\", line 18, in ans3a\n",
       "                score = silhouette_score(X, clusters)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 141, in silhouette_score\n",
       "                return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
       "                return func(*args, **kwargs)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 299, in silhouette_samples\n",
       "                check_number_of_labels(len(le.classes_), n_samples)\n",
       "              File \"/Users/renkhunag/.pyenv/versions/3.10.14/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py\", line 38, in check_number_of_labels\n",
       "                raise ValueError(\n",
       "            ValueError: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "##### 3b. Write a function that plots the dendrogram for your best cluster and confirm that your choice of cluster number is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "def ans3b(Z):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 4. Given to you is a generated dataset of 4 3D gaussian clusters with two overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def create_data():\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    cluster_1 = rng.normal(loc=[0, 0, 0], scale=1, size=(100, 3))\n",
    "    cluster_2 = rng.normal(loc=[5, 5, 5], scale=1, size=(100, 3))\n",
    "    cluster_3 = rng.normal(loc=[2, 2, 2], scale=1.5, size=(100, 3))\n",
    "    cluster_4 = rng.normal(loc=[8, 8, 8], scale=1, size=(100, 3))\n",
    "    X = np.vstack((cluster_1, cluster_2, cluster_3, cluster_4))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4a. Use Gaussian Mixture Models (GMM) to identify clusters. Return the `k_values, bics, and silhouette scores`. Please convert all values to `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### The Bayesian Information Criterion (BIC) is a statistical measure used to evaluate the goodness of fit of a model while penalizing for complexity.\n",
    "This is how it works:\n",
    "1. BIC assesses how well a model fits the data. **A lower BIC value** indicates a better fit.\n",
    "2. BIC includes a **penalty term** for the number of parameters in the model. (**Discourages overfitting**)\n",
    "3. **BIC = -2 log(L) + k log(n)**      ; L - Likelihood of the model, k - number of parameters, n - number of data points.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE:\n",
    "- Use `gmm.bic(X)` to find the `bic score` for a given k_value.\n",
    "- For `silhoutte score` computation, use the `labels of the data points` by performing gmm model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### K selection using BIC for GMMs - https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_gmm(X):\n",
    "    bics = []\n",
    "    silhouette_scores = []\n",
    "    k_values = range(2, 10)\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "4b. Determine the optimal k by using the `bic` metric to find the best number of clusters. Return the `best_k_bic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimal_k(X):\n",
    "    k_values, bics, silhouette_scores = evaluate_gmm(X)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "4c. Visualize clusters with the best k. Plot a 3D plot and color the points based on the `gmm labels`.\n",
    "Please make sure you `call the function` to display your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clusters(X):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    best_k = optimal_k(X)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 5. In this question we will implement GMM from scratch. We have filled up most of the code up for you, and require you to fill in the incomplete portions.\n",
    "#### Imagine you’re running a coffee shop and you have data on your customers’ preferences for coffee.\n",
    "\n",
    "##### Each customer likes a different blend of beans, which you can represent as a point in two dimensions: \n",
    "\n",
    "* sweetness (x-axis)\n",
    "* acidity (y-axis). \n",
    "\n",
    "##### Your goal is to `identify the three most popular blends (clusters)` from a pile of customer reviews that provide noisy measurements of these two characteristics.\n",
    "\n",
    "- To do this, we will implement `GMM using the EM algorithm` and cluster the data.\n",
    "1.\tExpectation Step (E-step): The model takes a guess about the `likelihood that each customer belongs to each blend`. At this point, it might not be sure, so it assigns probabilities `(soft assignments)` based on how close the customers’ preferences are to the different blends.\n",
    "2.\tMaximization Step (M-step): The model then `updates its guess about the actual parameters` of the coffee blends -- essentially `adjusting the mean, variance, and proportion of customers for each blend`, based on the soft assignments from the previous step.\n",
    "\n",
    "#### The EM algorithm is like refining a recipe. Each time you taste-test (E-step) and then tweak the ingredients (M-step), the blend becomes more representative of what customers want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def create_data_gmm():\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Means and covariances for three Gaussian distributions (coffee blends)\n",
    "    means = np.array([[2, 3], [8, 7], [5, 10]])  # sweetness and acidity means\n",
    "    covariances = [np.array([[1, 0.5], [0.5, 1]]),  # covariance matrix for blend 1\n",
    "                np.array([[1, -0.3], [-0.3, 1]]),  # covariance matrix for blend 2\n",
    "                np.array([[1, 0], [0, 1]])]  # covariance matrix for blend 3\n",
    "\n",
    "    # Number of points in each cluster (representing customers)\n",
    "    points_per_cluster = 100\n",
    "\n",
    "    # Generate points from each Gaussian distribution\n",
    "    X1 = np.random.multivariate_normal(means[0], covariances[0], points_per_cluster)\n",
    "    X2 = np.random.multivariate_normal(means[1], covariances[1], points_per_cluster)\n",
    "    X3 = np.random.multivariate_normal(means[2], covariances[2], points_per_cluster)\n",
    "\n",
    "    # Combine all points into one dataset\n",
    "    X = np.vstack((X1, X2, X3))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X = create_data_gmm()\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, color='b', label=\"Customers' coffee preferences\")\n",
    "plt.title('Synthetic Coffee Preferences Dataset')\n",
    "plt.xlabel('Sweetness')\n",
    "plt.ylabel('Acidity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### For the initialization of the parameters, we can do as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def initialize_params(X, n_clusters):\n",
    "    np.random.seed(42)\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    #Randomly initialize means from the data\n",
    "    means = X[np.random.choice(n_samples, n_clusters, False)]\n",
    "    \n",
    "    #initialize covariances as identity matrices\n",
    "    covariances = [np.eye(n_features) for _ in range(n_clusters)]\n",
    "    \n",
    "    #initialize equal weights for the mixture components\n",
    "    weights = np.ones(n_clusters) / n_clusters\n",
    "\n",
    "    return means, covariances, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5a) First, complete the code which would help perform the `expectation step` of the EM algorithm. \n",
    "- You are required to fill in the correct code that would compute the `responsibility` (posterior probability that a point belongs to a cluster)\n",
    "- Remember that the `responsibility calculation uses the initialized parameters` (means, covariances, and weights). \n",
    "- Use the `multivariate_normal` function to `compute the pdf` of the multivariate Gaussian.\n",
    "- Return the computed `responsibilities` array. Please don't forget to normalize the responsibilities before returning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "def expectation_step(X, means, covariances, weights):\n",
    "    n_samples, n_clusters = X.shape[0], len(means)\n",
    "    responsibilities = np.zeros((n_samples, n_clusters))     #initialize the responsibilities as a np array of 0s\n",
    "    #compute the responsibilities by iterating over each cluster (for each k, compute responsibilities)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5b) Secondly, complete the code which would help perform the `maximization step` of the EM algorithm. \n",
    "- In the below code, you are required to complete the code for `computing the covariances`.\n",
    "- As a refresher, the update formulas are given below.\n",
    "\n",
    "**Mean Update**\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac{\\sum_{i=1}^{N} \\gamma_{ik} x_i}{\\sum_{i=1}^{N} \\gamma_{ik}}\n",
    "$$\n",
    "\n",
    "\n",
    "**Covariance Update**\n",
    "\n",
    "$$\n",
    "\\Sigma_k = \\frac{\\sum_{i=1}^{N} \\gamma_{ik} (x_i - \\mu_k)(x_i - \\mu_k)^T}{\\sum_{i=1}^{N} \\gamma_{ik}}\n",
    "$$\n",
    "\n",
    "\n",
    "**Weights Update**\n",
    "\n",
    "$$\n",
    "\\pi_k = \\frac{\\sum_{i=1}^{N} \\gamma_{ik}}{N}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $\\gamma_{ik}$ is the responsibility of component $k$ for data point $i$.\n",
    "- $N$ is the total number of data points.\n",
    "- $x_i$ is the data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maximization_step(X, responsibilities):\n",
    "    n_samples, n_clusters = responsibilities.shape\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    #initialize parameters\n",
    "    means = np.zeros((n_clusters, n_features))\n",
    "    covariances = []\n",
    "    weights = np.zeros(n_clusters)\n",
    "    \n",
    "    for k in range(n_clusters):\n",
    "        # effective number of points assigned to cluster k\n",
    "        Nk = responsibilities[:, k].sum()\n",
    "        \n",
    "        #update the means\n",
    "        means[k] = (X * responsibilities[:, k][:, np.newaxis]).sum(axis=0) / Nk\n",
    "        #update the covariance matrices\n",
    "        covariance_k = np.zeros((n_features, n_features)) \n",
    "\n",
    "         \n",
    "        for i in range(n_samples):\n",
    "            ...\n",
    "        covariances.append(covariance_k / Nk)\n",
    "        \n",
    "        #update the weights (mixture proportions)\n",
    "        weights[k] = Nk / n_samples\n",
    "    \n",
    "    return means, covariances, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5c) Complete the code which would help compute the `log-likelihood` of the multivariate normal distribution using the `3 calculated parameters` (mean, covariance, and weights) from the EM steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Log-Likelihood Calculation:**\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{N} \\log \\left( \\sum_{k=1}^{K} \\pi_k \\cdot \\mathcal{N}(x_i \\mid \\mu_k, \\Sigma_k) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $\\log L(\\theta)$ is the log-likelihood of the parameters $\\theta$.\n",
    "- $N$ is the total number of data points.\n",
    "- $K$ is the number of components.\n",
    "- $\\pi_k$ is the mixing coefficient for component $k$.\n",
    "- $\\mathcal{N}(x_i \\mid \\mu_k, \\Sigma_k)$ is the Gaussian probability density function for data point $x_i$ given mean $\\mu_k$ and covariance $\\Sigma_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_likelihood(X, means, covariances, weights):\n",
    "    n_samples, n_clusters = X.shape[0], len(means)\n",
    "    log_likelihood = 0\n",
    "    ...\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5d) Write a function `em_algorithm` which would:\n",
    "1. `Initialize` the parameters\n",
    "2. Iteratively perform the `expectation step`\n",
    "3. Perform the `maximization step`\n",
    "4. Compute the`Log-likelihood` of the multivariate Gaussian\n",
    "5. Check for `convergence `\n",
    "6. Return `means, covariances, weights, responsibilities, log_likelihoods`\n",
    "\n",
    "- You can do this by calling the appropriate functions that you completed from 5a) through 5c) until step 4.\n",
    "- For step 5, check if the last and penultimate log likelihoods have a difference below a threshold value `tol` and break if that condition is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def em_algorithm(X, n_iters=100, tol=1e-4):\n",
    "    log_likelihoods = [] # use this list to store all the log-likelihood values\n",
    "    n_clusters = 3\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5e) Run the below code to visualize your GMM clusters means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "means, covariances, weights, responsibilities, log_likelihoods = em_algorithm(X, n_clusters)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, color='b', label=\"Data points\")\n",
    "plt.scatter(means[:, 0], means[:, 1], s=100, color='r', label=\"Estimated Means\", marker='x')\n",
    "plt.title('Clusters Found by Gaussian Mixture Model')\n",
    "plt.xlabel('Sweetness')\n",
    "plt.ylabel('Acidity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. \n",
    "Please submit the completed notebook on Gradescope to view your results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q3a": {
     "name": "q3a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n_samples = 300\n>>> n_features = 2\n>>> n_clusters = 4\n>>> random_state = 42\n>>> X, _ = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features, random_state=random_state)\n>>> assert ans3a(X)[1] == 'ward'\n>>> assert ans3a(X)[2] == 4\n>>> assert 0.75 < ans3a(X)[3] < 0.85\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = create_data()\n>>> assert 0.15 <= evaluate_gmm(X)[2][-1] <= 0.25\n>>> assert 0.5 <= evaluate_gmm(X)[2][0] <= 0.6\n>>> assert 0.35 <= evaluate_gmm(X)[2][4] <= 0.45\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = create_data()\n>>> assert optimal_k(X) == 4\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5a": {
     "name": "q5a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = create_data_gmm()\n>>> means, covariances, weights = initialize_params(X, 3)\n>>> assert expectation_step(X, means, covariances, weights).shape == (300, 3)\n>>> assert 0 < float(expectation_step(X, means, covariances, weights)[0][2]) <= 0.1\n>>> assert 0.2 < float(expectation_step(X, means, covariances, weights)[-1][1]) <= 0.3\n>>> assert 0.7 < float(expectation_step(X, means, covariances, weights)[-1][0]) <= 0.8\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5b": {
     "name": "q5b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = create_data_gmm()\n>>> means, covariances, weights = initialize_params(X, 3)\n>>> assert len(maximization_step(X, expectation_step(X, means, covariances, weights))[1]) == 3\n>>> assert maximization_step(X, expectation_step(X, means, covariances, weights))[1][0].shape == (2, 2)\n>>> assert 1.3 <= float(maximization_step(X, expectation_step(X, means, covariances, weights))[1][0][0][0]) <= 1.4\n>>> assert 2.5 <= float(maximization_step(X, expectation_step(X, means, covariances, weights))[1][0][1][1]) <= 2.7\n>>> assert 3.5 <= float(maximization_step(X, expectation_step(X, means, covariances, weights))[1][1][0][0]) <= 3.6\n>>> assert float(maximization_step(X, expectation_step(X, means, covariances, weights))[1][2][0][1]) == float(maximization_step(X, expectation_step(X, means, covariances, weights))[1][2][1][0])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5c": {
     "name": "q5c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = create_data_gmm()\n>>> means, covariances, weights = initialize_params(X, 3)\n>>> assert -1300 <= float(log_likelihood(X, maximization_step(X, expectation_step(X, means, covariances, weights))[0], maximization_step(X, expectation_step(X, means, covariances, weights))[1], maximization_step(X, expectation_step(X, means, covariances, weights))[2])) <= -1200\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5d": {
     "name": "q5d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = create_data_gmm()\n>>> assert -1200 <= float(em_algorithm(X)[4][-1]) <= -1100\n>>> assert 0.3 <= float(em_algorithm(X)[2][0]) <= 0.4\n>>> assert 0.9 < float(em_algorithm(X)[3][-1][0]) <= 1.0\n>>> assert 4.5 <= float(em_algorithm(X)[0][0][0]) <= 5.5\n>>> assert 0 <= em_algorithm(X)[1][0][1][0] == em_algorithm(X)[1][0][0][1] <= 0.1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
